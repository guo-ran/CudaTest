### CUDA优化实践之尽可能使用向量化内存操作

Nvidia性能优化的博客[Increase Performance with Vectorized Memory Access](https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/ )中提到可以通过向量化内存操作来提高Cuda Kernel性能，大多数的Cuda Kernel都是带宽受限的，使用向量化内存操作可以减少总的指令数，减少延迟，提高带宽利用率。文中比较了不同ArraySize下使用vector2、vector4向量化访存相对scalar访存的性能，发现向量化读写内存在任何情况下都会相比普通读写有性能提升。

几年过去了，我们在最新的硬件上做了实验来评估向量化内存操作对Cuda Kernel性能的提升，我们分别在GeForce RTX 2080 Ti ，GeForce RTX 3090、Tesla V100-SXM2-32GB及NVIDIA A100-PCIE-40GB上进行了测试，测试Array Size从1MB-1024MB，读写内存单位从1Byte-16Byte下，性能的变化。

#### 实验：

下图中横轴代表数据量大小从1MB-1024MB变化，纵轴代表Copy操作达到的有效显存读写带宽(越高越好)，每条线代表从1Byte-16Byte的global memory访存单位，可以看到总体的趋势是随着数据量增大，达到的有效显存读写带宽越高，当数据量到一定范围后，达到的有效显存读写带宽趋于稳定，接近设备理论显存带宽。global memory访存单位越大，达到的有效显存读写带宽越高。


NVIDIA A100-PCIE-40GB


|       | 1B     | 2B     | 4B      | 8B      | 16B     |
| ----- | ------ | ------ | ------- | ------- | ------- |
| 1M    | 87.87  | 111.47 | 120.06  | 139.47  | 134.86  |
| 2M    | 120.26 | 171.12 | 208.73  | 218.47  | 231.59  |
| 4M    | 145.8  | 232.82 | 319.71  | 354.27  | 341.34  |
| 8M    | 164.67 | 283.71 | 431.16  | 488.17  | 493.84  |
| 16M   | 200.59 | 365.12 | 581.72  | 697.82  | 712.07  |
| 32M   | 265.6  | 503.41 | 830.7   | 1044.48 | 1085.44 |
| 64M   | 300.36 | 574.24 | 961.68  | 1228.8  | 1269.76 |
| 128M  | 316.85 | 608.89 | 1054.72 | 1320.96 | 1361.92 |
| 256M  | 327.76 | 627.55 | 1095.68 | 1351.68 | 1392.64 |
| 512M  | 334.57 | 635.59 | 1116.16 | 1372.16 | 1413.12 |
| 1024M | 338.12 | 639.86 | 1126.4  | 1382.4  | 1423.36 |

![image-20211013152912717](image/image-a100.png)

由图上可以看出对于NVIDIA A100-PCIE-40GB显卡，Global Memory访存单位为8Byte和16Byte的性能接近，访存单位为4Byte与8Byte有显著性能差距，2Byte相对于4Byte也有显著性能差距。说明对于常见的数据操作类型为float类型或half类型的CUDA Kernel，如果不能将几个元素的Global Memory访存操作pack到一起读写，而是一个元素一个元素操作，就一定会有性能问题。



Tesla V100-SXM2-32GB


|       | 1B     | 2B     | 4B      | 8B      | 16B     |
| ----- | ------ | ------ | ------- | ------- | ------- |
| 1M    | 87.87  | 111.47 | 120.06  | 139.47  | 134.86  |
| 2M    | 120.26 | 171.12 | 208.73  | 218.47  | 231.59  |
| 4M    | 145.8  | 232.82 | 319.71  | 354.27  | 341.34  |
| 8M    | 164.67 | 283.71 | 431.16  | 488.17  | 493.84  |
| 16M   | 200.59 | 365.12 | 581.72  | 697.82  | 712.07  |
| 32M   | 265.6  | 503.41 | 830.7   | 1044.48 | 1085.44 |
| 64M   | 300.36 | 574.24 | 961.68  | 1228.8  | 1269.76 |
| 128M  | 316.85 | 608.89 | 1054.72 | 1320.96 | 1361.92 |
| 256M  | 327.76 | 627.55 | 1095.68 | 1351.68 | 1392.64 |
| 512M  | 334.57 | 635.59 | 1116.16 | 1372.16 | 1413.12 |
| 1024M | 338.12 | 639.86 | 1126.4  | 1382.4  | 1423.36 |

![image-20211013152942847](image/image-v100.png)

由图上可以看出对于Tesla V100-SXM2-32GB显卡，Global Memory访存单位为4Byte、8Byte和16Byte的性能接近，访存单位为2Byte相对于4Byte有显著性能差距。说明对于常见的数据操作类型为float类型的Kernel，不把多个元素pack到一起读写，一个个操作，不会有明显的性能问题。而对于half类型，如果不能将几个元素的Global Memory访存操作pack到一起读写，而是一个元素一个元素操作，就一定会有性能问题。



NVIDIA GeForce RTX 3090



|       | 1B     | 2B     | 4B     | 8B     | 16B    |
| ----- | ------ | ------ | ------ | ------ | ------ |
| 1M    | 130.09 | 178.93 | 216.2  | 237.72 | 242.73 |
| 2M    | 154.55 | 236.9  | 285.12 | 311.85 | 327.94 |
| 4M    | 223.71 | 358.08 | 438.51 | 454.12 | 476.03 |
| 8M    | 301.91 | 511.81 | 626.91 | 647.04 | 642.87 |
| 16M   | 345.33 | 598.02 | 736.31 | 731.32 | 732.74 |
| 32M   | 367.42 | 647.05 | 794.96 | 788.7  | 781.61 |
| 64M   | 376.84 | 667.92 | 824.81 | 814.57 | 816.26 |
| 128M  | 382.96 | 680.56 | 841.24 | 829.76 | 831.64 |
| 256M  | 386.17 | 686.9  | 848.15 | 838.7  | 834.53 |
| 512M  | 387.76 | 689.87 | 852.74 | 840.73 | 841.66 |
| 1024M | 388.13 | 691.14 | 854.78 | 844.73 | 843.99 |


![image-20211013152951303](image/image-3090.png)



GeForce RTX 2080 Ti 

|       | 1B     | 2B     | 4B     | 8B     | 16B    |
| ----- | ------ | ------ | ------ | ------ | ------ |
| 1M    | 130.09 | 178.93 | 216.2  | 237.72 | 242.73 |
| 2M    | 154.55 | 236.9  | 285.12 | 311.85 | 327.94 |
| 4M    | 223.71 | 358.08 | 438.51 | 454.12 | 476.03 |
| 8M    | 301.91 | 511.81 | 626.91 | 647.04 | 642.87 |
| 16M   | 345.33 | 598.02 | 736.31 | 731.32 | 732.74 |
| 32M   | 367.42 | 647.05 | 794.96 | 788.7  | 781.61 |
| 64M   | 376.84 | 667.92 | 824.81 | 814.57 | 816.26 |
| 128M  | 382.96 | 680.56 | 841.24 | 829.76 | 831.64 |
| 256M  | 386.17 | 686.9  | 848.15 | 838.7  | 834.53 |
| 512M  | 387.76 | 689.87 | 852.74 | 840.73 | 841.66 |
| 1024M | 388.13 | 691.14 | 854.78 | 844.73 | 843.99 |


![image-20211013154007210](image/image-2080Ti.png)

在由图上可以看出对于NVIDIA GeForce RTX 3090和GeForce RTX 2080 Ti 显卡，Global Memory访存单位为4Byte、8Byte和16Byte的性能几乎重合，访存单位为2Byte相对于4Byte有显著性能差距。说明对于常见的数据操作类型为float类型的Kernel，不需要把多个元素pack到一起读写。而对于half类型，如果不能将几个元素的Global Memory访存操作pack到一起读写，而是一个元素一个元素操作，就一定会有性能问题。


#### 实验结论：

在Tesla V100及以下的显卡上，对于float类型数据的访存操作，不需要把多个元素合并到一起向量化读写，但是half类型一定需要合并到4Byte及以上向量化访存，才能更好利用带宽资源。

在A100显卡以后，4Byte大小的float类型数据的访存操作也需要合并到8Byte及以上向量化访存才能更好利用带宽资源。


#### 如何处理：

在A100显卡以后，需要考虑float数据类型的向量化访存操作，half类型合并到half2访存仍无法最好利用带宽，应该合并到8Byte以上。

对于纯数据移动类操作，可以直接合并读写。

```
    using T = typename std::aligned_storage<N, N>::type;
    const T* src = reinterpret_cast<const T*>(in);
    T* dst = reinterpret_cast<T*>(out);
    dst[i] = src[i];
```

对于有计算的操作可以用union 转换数据，借助Pack结构，将数据读到Pack.storage中，使用pack.elem逐个参与计算

```
template<typename T, int N>
struct GetPackType {
  using type = typename std::aligned_storage<N * sizeof(T), N * sizeof(T)>::type;
};

template<typename T, int N>
using PackType = typename GetPackType<T, N>::type;

template<typename T, int N>
union Pack {
  static_assert(sizeof(PackType<T, N>) == sizeof(T) * N, "");
  __device__ Pack() {
    // do nothing
  }
  PackType<T, N> storage;
  T elem[N];
};
```
















